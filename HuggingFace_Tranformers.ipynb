{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "862cf148",
   "metadata": {},
   "source": [
    "# Example Code : NLP with Transformers\n",
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c992bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: A space was detected in your requested environment path:\n",
      "'C:\\Users\\Chirag Sharma\\anaconda3\\envs\\hf-env'\n",
      "Spaces in paths can sometimes be problematic. To minimize issues,\n",
      "make sure you activate your environment before running any executables!\n",
      "\n",
      "\n",
      "ResolvePackageNotFound: \n",
      "  - tk==8.6.12=h5d9f67b_0\n",
      "  - bzip2==1.0.8=h1de35cc_0\n",
      "  - markupsafe==2.1.3=py310h6729b98_0\n",
      "  - cffi==1.15.1=py310ha78151a_3\n",
      "  - sqlite==3.41.2=h6c40b1e_0\n",
      "  - tornado==6.3.2=py310h6729b98_0\n",
      "  - ncurses==6.4=hcec6c5f_0\n",
      "  - debugpy==1.6.7=py310h7a76584_0\n",
      "  - pyobjc-framework-cocoa==9.2=py310hef2d279_0\n",
      "  - pip==23.2.1=py310hecd8cb5_0\n",
      "  - xz==5.4.2=h6c40b1e_0\n",
      "  - wheel==0.38.4=py310hecd8cb5_0\n",
      "  - rpds-py==0.9.2=py310h3461e44_0\n",
      "  - brotli-python==1.0.9=py310h7a76584_9\n",
      "  - jupyter_core==5.3.1=py310h2ec42d9_0\n",
      "  - pyobjc-core==9.2=py310hef2d279_0\n",
      "  - argon2-cffi-bindings==21.2.0=py310h90acd4f_3\n",
      "  - psutil==5.9.5=py310h90acd4f_0\n",
      "  - zlib==1.2.13=h4dc903c_0\n",
      "  - yaml==0.2.5=h0d85af4_2\n",
      "  - openssl==3.1.1=h8a1eda9_1\n",
      "  - libsodium==1.0.18=hbcb3906_1\n",
      "  - zeromq==4.3.4=he49afe7_1\n",
      "  - ca-certificates==2023.7.22=h8857fd0_0\n",
      "  - setuptools==68.0.0=py310hecd8cb5_0\n",
      "  - python==3.10.12=h5ee71fb_0\n",
      "  - pyzmq==25.1.0=py310h998be00_0\n",
      "  - libcxx==16.0.6=hd57cbcb_0\n",
      "  - libffi==3.4.4=hecd8cb5_0\n",
      "  - readline==8.2=hca72f7f_0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env create --file hf-env.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e9c319c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998743534088135}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\")\n",
    "pipe(\"This restaurant is awesome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3fa725a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# defining classifier \n",
    "classifier = pipeline(task=\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e47b94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9997244477272034}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"Hate this\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd784e30",
   "metadata": {},
   "source": [
    "## Batch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "216e8055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998785257339478},\n",
       " {'label': 'POSITIVE', 'score': 0.9981271624565125},\n",
       " {'label': 'NEGATIVE', 'score': 0.9996721744537354},\n",
       " {'label': 'POSITIVE', 'score': 0.9997714161872864}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can also pass a list to classify \n",
    "text_list = [\"This is great\", \\\n",
    "             \"Thank you for nothing\", \\\n",
    "             \"You have got a bad face\",\\\n",
    "             \"You are beautiful, never change!\"]\n",
    "\n",
    "classifier(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58846007",
   "metadata": {},
   "source": [
    "## Multiple Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06bee365",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# if there are multiple target labels, we can return them all\n",
    "classifier = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "005ae3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'admiration', 'score': 0.9526104927062988},\n",
       "  {'label': 'approval', 'score': 0.030472060665488243},\n",
       "  {'label': 'neutral', 'score': 0.015236252918839455},\n",
       "  {'label': 'excitement', 'score': 0.006063755135983229},\n",
       "  {'label': 'gratitude', 'score': 0.005296214483678341},\n",
       "  {'label': 'joy', 'score': 0.004475208930671215},\n",
       "  {'label': 'curiosity', 'score': 0.004322345834225416},\n",
       "  {'label': 'realization', 'score': 0.004089605528861284},\n",
       "  {'label': 'optimism', 'score': 0.004077206831425428},\n",
       "  {'label': 'disapproval', 'score': 0.004076544661074877},\n",
       "  {'label': 'annoyance', 'score': 0.003528754459694028},\n",
       "  {'label': 'surprise', 'score': 0.0029730629175901413},\n",
       "  {'label': 'disappointment', 'score': 0.0027346303686499596},\n",
       "  {'label': 'love', 'score': 0.0026945844292640686},\n",
       "  {'label': 'amusement', 'score': 0.002486748620867729},\n",
       "  {'label': 'confusion', 'score': 0.002360741840675473},\n",
       "  {'label': 'pride', 'score': 0.0021013221703469753},\n",
       "  {'label': 'sadness', 'score': 0.001773050636984408},\n",
       "  {'label': 'anger', 'score': 0.0017196948174387217},\n",
       "  {'label': 'caring', 'score': 0.0013670107582584023},\n",
       "  {'label': 'desire', 'score': 0.0010478701442480087},\n",
       "  {'label': 'disgust', 'score': 0.000968990963883698},\n",
       "  {'label': 'fear', 'score': 0.0005249759997241199},\n",
       "  {'label': 'relief', 'score': 0.00048620926099829376},\n",
       "  {'label': 'embarrassment', 'score': 0.0003417502448428422},\n",
       "  {'label': 'grief', 'score': 0.00033891823841258883},\n",
       "  {'label': 'remorse', 'score': 0.0002780948707368225},\n",
       "  {'label': 'nervousness', 'score': 0.00020788346591871232}]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(text_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fca7ae",
   "metadata": {},
   "source": [
    "## Conversational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2bf6fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBlenderbotForConditionalGeneration.\n",
      "\n",
      "Some layers of TFBlenderbotForConditionalGeneration were not initialized from the model checkpoint at facebook/blenderbot-400M-distill and are newly initialized: ['final_logits_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Conversation\n",
    "chatbot = pipeline(model=\"facebook/blenderbot-400M-distill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58b82f92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conversation = \"Hi I'm Shaw, how are you?\"\n",
    "conversation = chatbot(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a2ca2cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \" I'm doing well, how are you? I'm a little tired, I just got back from a long day of work.\"}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3697c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = chatbot(\"Where do you work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c844000f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \" I work at a grocery store as a cashier. It's not the most exciting job in the world, but it pays the bills.\"}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bed92db",
   "metadata": {},
   "source": [
    "# Using Gradio\n",
    "### Gradio\n",
    "An open source python package that allows to quicly build demo or web application for machine learning models, API, or any arbitrary pytho function, without any javascript, css or web hosting. \n",
    "\n",
    "Allows locally using the demo, but can also provide a sharable link using share=True in launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c9c89027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-4.37.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from gradio) (22.1.0)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio)\n",
      "  Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting fastapi (from gradio)\n",
      "  Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting gradio-client==1.0.2 (from gradio)\n",
      "  Downloading gradio_client-1.0.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from gradio) (0.23.4)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from gradio) (1.24.3)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.6-cp311-none-win_amd64.whl.metadata (51 kB)\n",
      "     ---------------------------------------- 0.0/51.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 51.6/51.6 kB 2.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from gradio) (23.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from gradio) (9.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from gradio) (2.7.4)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from gradio) (6.0)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.5.0-py3-none-win_amd64.whl.metadata (24 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Collecting urllib3~=2.0 (from gradio)\n",
      "  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from gradio-client==1.0.2->gradio) (2024.6.0)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio-client==1.0.2->gradio)\n",
      "  Downloading websockets-11.0.3-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (3.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2022.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (2.18.4)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.0.4)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
      "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from fastapi->gradio) (5.4.0)\n",
      "Collecting email_validator>=2.0.0 (from fastapi->gradio)\n",
      "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
      "  Downloading httptools-0.6.1-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
      "  Downloading watchfiles-0.22.0-cp311-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.4)\n",
      "INFO: pip is looking at multiple versions of requests to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting requests (from huggingface-hub>=0.19.3->gradio)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\chirag sharma\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Downloading gradio-4.37.2-py3-none-any.whl (12.3 MB)\n",
      "   ---------------------------------------- 0.0/12.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/12.3 MB 7.6 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.1/12.3 MB 14.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 1.8/12.3 MB 14.3 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.1/12.3 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.8/12.3 MB 23.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.0/12.3 MB 18.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.3/12.3 MB 20.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.8/12.3 MB 19.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.2/12.3 MB 18.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.6/12.3 MB 16.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.1/12.3 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.5/12.3 MB 17.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.2/12.3 MB 17.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.7/12.3 MB 17.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.9/12.3 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.0/12.3 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.3 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.3/12.3 MB 15.6 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.0.2-py3-none-any.whl (318 kB)\n",
      "   ---------------------------------------- 0.0/318.2 kB ? eta -:--:--\n",
      "   ---------------------------------------  317.4/318.2 kB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 318.2/318.2 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "   ---------------------------------------- 0.0/857.8 kB ? eta -:--:--\n",
      "   --------------- ----------------------- 337.9/857.8 kB 10.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 624.6/857.8 kB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  849.9/857.8 kB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 857.8/857.8 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading orjson-3.10.6-cp311-none-win_amd64.whl (136 kB)\n",
      "   ---------------------------------------- 0.0/136.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 136.4/136.4 kB 7.9 MB/s eta 0:00:00\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading ruff-0.5.0-py3-none-win_amd64.whl (8.5 MB)\n",
      "   ---------------------------------------- 0.0/8.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/8.5 MB 7.4 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.7/8.5 MB 7.4 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.0/8.5 MB 7.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.4/8.5 MB 7.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.6/8.5 MB 7.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.7/8.5 MB 6.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.1/8.5 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.4/8.5 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.8/8.5 MB 6.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.1/8.5 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 3.5/8.5 MB 6.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 3.8/8.5 MB 6.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.2/8.5 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 4.4/8.5 MB 6.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 4.6/8.5 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.9/8.5 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.2/8.5 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.4/8.5 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 5.6/8.5 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 5.8/8.5 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.0/8.5 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.1/8.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.3/8.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.5/8.5 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.7/8.5 MB 5.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.0/8.5 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.3/8.5 MB 5.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.6/8.5 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.0/8.5 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.3/8.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.5/8.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.5/8.5 MB 5.7 MB/s eta 0:00:00\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 47.2/47.2 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
      "   ---------------------------------------- 0.0/121.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 121.4/121.4 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.4/62.4 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "   ---------------------------------------- 0.0/92.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 92.0/92.0 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.9/71.9 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading websockets-11.0.3-cp311-cp311-win_amd64.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/124.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 124.7/124.7 kB 3.6 MB/s eta 0:00:00\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "   ---------------------------------------- 0.0/307.7 kB ? eta -:--:--\n",
      "   ---------------------------------------  307.2/307.7 kB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 307.7/307.7 kB 4.7 MB/s eta 0:00:00\n",
      "Downloading httptools-0.6.1-cp311-cp311-win_amd64.whl (55 kB)\n",
      "   ---------------------------------------- 0.0/55.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 55.4/55.4 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading watchfiles-0.22.0-cp311-none-win_amd64.whl (281 kB)\n",
      "   ---------------------------------------- 0.0/282.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 282.0/282.0 kB 5.8 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py): started\n",
      "  Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5606 sha256=64caa967b9280dbf814a88623ef2b36aca4107a097fc4dae85cbeaddd203b665\n",
      "  Stored in directory: c:\\users\\chirag sharma\\appdata\\local\\pip\\cache\\wheels\\55\\3c\\f2\\f6e34046bac0d57c13c7d08123b85872423b89c8f59bafda51\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: pydub, ffmpy, websockets, urllib3, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, orjson, importlib-resources, httptools, dnspython, watchfiles, uvicorn, starlette, requests, email_validator, typer, altair, gradio-client, fastapi-cli, fastapi, gradio\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.16\n",
      "    Uninstalling urllib3-1.26.16:\n",
      "      Successfully uninstalled urllib3-1.26.16\n",
      "  Attempting uninstall: tomlkit\n",
      "    Found existing installation: tomlkit 0.11.1\n",
      "    Uninstalling tomlkit-0.11.1:\n",
      "      Successfully uninstalled tomlkit-0.11.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.29.0\n",
      "    Uninstalling requests-2.29.0:\n",
      "      Successfully uninstalled requests-2.29.0\n",
      "Successfully installed altair-5.3.0 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.37.2 gradio-client-1.0.2 httptools-0.6.1 importlib-resources-6.4.0 orjson-3.10.6 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 requests-2.32.3 ruff-0.5.0 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 typer-0.12.3 urllib3-2.2.2 uvicorn-0.30.1 watchfiles-0.22.0 websockets-11.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.41 requires requests_mock, which is not installed.\n",
      "botocore 1.27.59 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires nbformat==5.4.0, but you have nbformat 5.7.0 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires requests==2.28.1, but you have requests 2.32.3 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a704355f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_list = []\n",
    "response_list = []\n",
    "\n",
    "def vanilla_chatbot(message, history):\n",
    "    conversation = chatbot(message)\n",
    "    \n",
    "    return conversation[0]['generated_text']\n",
    "\n",
    "demo_chatbot = gr.ChatInterface(vanilla_chatbot, title=\"Vanilla Chabot\", description=\"Enter text to start chatting\")\n",
    "\n",
    "demo_chatbot.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4d72d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
